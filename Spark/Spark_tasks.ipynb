{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "Spark homework"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "from pyspark import SparkContext, SparkConf\r\n",
                "from pyspark.sql import SparkSession"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Start Spark session"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "spark = SparkSession.builder \\\r\n",
                "    .master('local') \\\r\n",
                "    .appName('Spark-Homework') \\\r\n",
                "    .getOrCreate()\r\n",
                "spark"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "WARNING: An illegal reflective access operation has occurred\n",
                        "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
                        "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
                        "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
                        "WARNING: All illegal access operations will be denied in a future release\n",
                        "21/08/25 13:42:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
                        "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
                        "Setting default log level to \"WARN\".\n",
                        "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "<pyspark.sql.session.SparkSession at 0x7fcb5a9f02b0>"
                        ],
                        "text/html": [
                            "\n",
                            "            <div>\n",
                            "                <p><b>SparkSession - in-memory</b></p>\n",
                            "                \n",
                            "        <div>\n",
                            "            <p><b>SparkContext</b></p>\n",
                            "\n",
                            "            <p><a href=\"http://06921e5066bb:4040\">Spark UI</a></p>\n",
                            "\n",
                            "            <dl>\n",
                            "              <dt>Version</dt>\n",
                            "                <dd><code>v3.1.2</code></dd>\n",
                            "              <dt>Master</dt>\n",
                            "                <dd><code>local</code></dd>\n",
                            "              <dt>AppName</dt>\n",
                            "                <dd><code>Spark-Homework</code></dd>\n",
                            "            </dl>\n",
                            "        </div>\n",
                            "        \n",
                            "            </div>\n",
                            "        "
                        ]
                    },
                    "metadata": {},
                    "execution_count": 2
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Task 1 \r\n",
                "```\r\n",
                "Upload generated train.parquet , destinations.csv, struct_cities.json files from previous module Homework to Jupyter workspace. Create dataframes  and tempViews upon the files.\r\n",
                "```"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "HDFS_HOST = '172.17.0.3'\r\n",
                "WAREHOUSE_PATH = '/user/hive/warehouse'\r\n",
                "\r\n",
                "\r\n",
                "paths =  {'destinations' : 'hdfs://172.17.0.2/user/hive/warehouse/destinations/destinations.csv',\r\n",
                "        'struct_cities': 'hdfs://172.17.0.2/user/hive/warehouse/struct_cities/struct_cities.json',\r\n",
                "        'train': 'hdfs://172.17.0.2/user/hive/warehouse/staging/train.parquet/'}\r\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Read parquet file"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "train_df = spark.read.parquet(f'hdfs://{HDFS_HOST}/{WAREHOUSE_PATH}/staging/train.parquet',\r\n",
                "                        header = 'true',\r\n",
                "                        inferSchema = True\r\n",
                "                                )\r\n",
                "train_df.printSchema()\r\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "root\n",
                        " |-- date_time: string (nullable = true)\n",
                        " |-- site_name: integer (nullable = true)\n",
                        " |-- posa_continent: integer (nullable = true)\n",
                        " |-- user_location_country: integer (nullable = true)\n",
                        " |-- user_location_region: integer (nullable = true)\n",
                        " |-- user_location_city: integer (nullable = true)\n",
                        " |-- orig_destination_distance: double (nullable = true)\n",
                        " |-- user_id: integer (nullable = true)\n",
                        " |-- is_mobile: integer (nullable = true)\n",
                        " |-- is_package: integer (nullable = true)\n",
                        " |-- channel: integer (nullable = true)\n",
                        " |-- srch_ci: string (nullable = true)\n",
                        " |-- srch_co: string (nullable = true)\n",
                        " |-- srch_adults_cnt: integer (nullable = true)\n",
                        " |-- srch_children_cnt: integer (nullable = true)\n",
                        " |-- srch_rm_cnt: integer (nullable = true)\n",
                        " |-- srch_destination_id: integer (nullable = true)\n",
                        " |-- srch_destination_type_id: integer (nullable = true)\n",
                        " |-- is_booking: integer (nullable = true)\n",
                        " |-- cnt: integer (nullable = true)\n",
                        " |-- hotel_continent: integer (nullable = true)\n",
                        " |-- hotel_country: integer (nullable = true)\n",
                        " |-- hotel_market: integer (nullable = true)\n",
                        " |-- hotel_cluster: integer (nullable = true)\n",
                        "\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Read json"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "struct_cities_df = spark.read.json(f'hdfs://{HDFS_HOST}/{WAREHOUSE_PATH}/struct_cities/struct_cities.json')\r\n",
                "struct_cities_df.printSchema()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "struct_cities_df.show(3, truncate = False, vertical = True)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "-RECORD 0----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
                        " cities       | [{FALSE, FALSE, FALSE, Santa Cruz BalanyГЎ, 0, America/Guatemala}, {FALSE, TRUE, TRUE, San Pedro SacatepГ©quez, 0, America/Guatemala}]                         \n",
                        " country_code | 0                                                                                                                                                              \n",
                        "-RECORD 1----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
                        " cities       | [{FALSE, FALSE, TRUE, AtyrГЎ, 1, America/Asuncion}, {FALSE, FALSE, FALSE, Antequera, 1, America/Asuncion}]                                                     \n",
                        " country_code | 1                                                                                                                                                              \n",
                        "-RECORD 2----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
                        " cities       | [{FALSE, FALSE, TRUE, Limassol, 100, Asia/Nicosia}, {FALSE, FALSE, FALSE, Mammari, 100, Asia/Nicosia}, {FALSE, FALSE, TRUE, MosfilotГ-xad, 100, Asia/Nicosia}] \n",
                        " country_code | 100                                                                                                                                                            \n",
                        "only showing top 3 rows\n",
                        "\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Read csv"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "destinations_df = spark.read.csv(f'hdfs://{HDFS_HOST}/{WAREHOUSE_PATH}/destinations/destinations.csv',\r\n",
                "                        header = 'true',\r\n",
                "                        inferSchema = True\r\n",
                "                                )\r\n",
                "destinations_df.printSchema()"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": []
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "root\n",
                        " |-- srch_destination_id: integer (nullable = true)\n",
                        " |-- d1: double (nullable = true)\n",
                        " |-- d2: double (nullable = true)\n",
                        " |-- d3: double (nullable = true)\n",
                        " |-- d4: double (nullable = true)\n",
                        " |-- d5: double (nullable = true)\n",
                        " |-- d6: double (nullable = true)\n",
                        " |-- d7: double (nullable = true)\n",
                        " |-- d8: double (nullable = true)\n",
                        " |-- d9: double (nullable = true)\n",
                        " |-- d10: double (nullable = true)\n",
                        " |-- d11: double (nullable = true)\n",
                        " |-- d12: double (nullable = true)\n",
                        " |-- d13: double (nullable = true)\n",
                        " |-- d14: double (nullable = true)\n",
                        " |-- d15: double (nullable = true)\n",
                        " |-- d16: double (nullable = true)\n",
                        " |-- d17: double (nullable = true)\n",
                        " |-- d18: double (nullable = true)\n",
                        " |-- d19: double (nullable = true)\n",
                        " |-- d20: double (nullable = true)\n",
                        " |-- d21: double (nullable = true)\n",
                        " |-- d22: double (nullable = true)\n",
                        " |-- d23: double (nullable = true)\n",
                        " |-- d24: double (nullable = true)\n",
                        " |-- d25: double (nullable = true)\n",
                        " |-- d26: double (nullable = true)\n",
                        " |-- d27: double (nullable = true)\n",
                        " |-- d28: double (nullable = true)\n",
                        " |-- d29: double (nullable = true)\n",
                        " |-- d30: double (nullable = true)\n",
                        " |-- d31: double (nullable = true)\n",
                        " |-- d32: double (nullable = true)\n",
                        " |-- d33: double (nullable = true)\n",
                        " |-- d34: double (nullable = true)\n",
                        " |-- d35: double (nullable = true)\n",
                        " |-- d36: double (nullable = true)\n",
                        " |-- d37: double (nullable = true)\n",
                        " |-- d38: double (nullable = true)\n",
                        " |-- d39: double (nullable = true)\n",
                        " |-- d40: double (nullable = true)\n",
                        " |-- d41: double (nullable = true)\n",
                        " |-- d42: double (nullable = true)\n",
                        " |-- d43: double (nullable = true)\n",
                        " |-- d44: double (nullable = true)\n",
                        " |-- d45: double (nullable = true)\n",
                        " |-- d46: double (nullable = true)\n",
                        " |-- d47: double (nullable = true)\n",
                        " |-- d48: double (nullable = true)\n",
                        " |-- d49: double (nullable = true)\n",
                        " |-- d50: double (nullable = true)\n",
                        " |-- d51: double (nullable = true)\n",
                        " |-- d52: double (nullable = true)\n",
                        " |-- d53: double (nullable = true)\n",
                        " |-- d54: double (nullable = true)\n",
                        " |-- d55: double (nullable = true)\n",
                        " |-- d56: double (nullable = true)\n",
                        " |-- d57: double (nullable = true)\n",
                        " |-- d58: double (nullable = true)\n",
                        " |-- d59: double (nullable = true)\n",
                        " |-- d60: double (nullable = true)\n",
                        " |-- d61: double (nullable = true)\n",
                        " |-- d62: double (nullable = true)\n",
                        " |-- d63: double (nullable = true)\n",
                        " |-- d64: double (nullable = true)\n",
                        " |-- d65: double (nullable = true)\n",
                        " |-- d66: double (nullable = true)\n",
                        " |-- d67: double (nullable = true)\n",
                        " |-- d68: double (nullable = true)\n",
                        " |-- d69: double (nullable = true)\n",
                        " |-- d70: double (nullable = true)\n",
                        " |-- d71: double (nullable = true)\n",
                        " |-- d72: double (nullable = true)\n",
                        " |-- d73: double (nullable = true)\n",
                        " |-- d74: double (nullable = true)\n",
                        " |-- d75: double (nullable = true)\n",
                        " |-- d76: double (nullable = true)\n",
                        " |-- d77: double (nullable = true)\n",
                        " |-- d78: double (nullable = true)\n",
                        " |-- d79: double (nullable = true)\n",
                        " |-- d80: double (nullable = true)\n",
                        " |-- d81: double (nullable = true)\n",
                        " |-- d82: double (nullable = true)\n",
                        " |-- d83: double (nullable = true)\n",
                        " |-- d84: double (nullable = true)\n",
                        " |-- d85: double (nullable = true)\n",
                        " |-- d86: double (nullable = true)\n",
                        " |-- d87: double (nullable = true)\n",
                        " |-- d88: double (nullable = true)\n",
                        " |-- d89: double (nullable = true)\n",
                        " |-- d90: double (nullable = true)\n",
                        " |-- d91: double (nullable = true)\n",
                        " |-- d92: double (nullable = true)\n",
                        " |-- d93: double (nullable = true)\n",
                        " |-- d94: double (nullable = true)\n",
                        " |-- d95: double (nullable = true)\n",
                        " |-- d96: double (nullable = true)\n",
                        " |-- d97: double (nullable = true)\n",
                        " |-- d98: double (nullable = true)\n",
                        " |-- d99: double (nullable = true)\n",
                        " |-- d100: double (nullable = true)\n",
                        " |-- d101: double (nullable = true)\n",
                        " |-- d102: double (nullable = true)\n",
                        " |-- d103: double (nullable = true)\n",
                        " |-- d104: double (nullable = true)\n",
                        " |-- d105: double (nullable = true)\n",
                        " |-- d106: double (nullable = true)\n",
                        " |-- d107: double (nullable = true)\n",
                        " |-- d108: double (nullable = true)\n",
                        " |-- d109: double (nullable = true)\n",
                        " |-- d110: double (nullable = true)\n",
                        " |-- d111: double (nullable = true)\n",
                        " |-- d112: double (nullable = true)\n",
                        " |-- d113: double (nullable = true)\n",
                        " |-- d114: double (nullable = true)\n",
                        " |-- d115: double (nullable = true)\n",
                        " |-- d116: double (nullable = true)\n",
                        " |-- d117: double (nullable = true)\n",
                        " |-- d118: double (nullable = true)\n",
                        " |-- d119: double (nullable = true)\n",
                        " |-- d120: double (nullable = true)\n",
                        " |-- d121: double (nullable = true)\n",
                        " |-- d122: double (nullable = true)\n",
                        " |-- d123: double (nullable = true)\n",
                        " |-- d124: double (nullable = true)\n",
                        " |-- d125: double (nullable = true)\n",
                        " |-- d126: double (nullable = true)\n",
                        " |-- d127: double (nullable = true)\n",
                        " |-- d128: double (nullable = true)\n",
                        " |-- d129: double (nullable = true)\n",
                        " |-- d130: double (nullable = true)\n",
                        " |-- d131: double (nullable = true)\n",
                        " |-- d132: double (nullable = true)\n",
                        " |-- d133: double (nullable = true)\n",
                        " |-- d134: double (nullable = true)\n",
                        " |-- d135: double (nullable = true)\n",
                        " |-- d136: double (nullable = true)\n",
                        " |-- d137: double (nullable = true)\n",
                        " |-- d138: double (nullable = true)\n",
                        " |-- d139: double (nullable = true)\n",
                        " |-- d140: double (nullable = true)\n",
                        " |-- d141: double (nullable = true)\n",
                        " |-- d142: double (nullable = true)\n",
                        " |-- d143: double (nullable = true)\n",
                        " |-- d144: double (nullable = true)\n",
                        " |-- d145: double (nullable = true)\n",
                        " |-- d146: double (nullable = true)\n",
                        " |-- d147: double (nullable = true)\n",
                        " |-- d148: double (nullable = true)\n",
                        " |-- d149: double (nullable = true)\n",
                        "\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": []
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Create temp Views"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "source": [
                "train_df.createOrReplaceTempView('train')\r\n",
                "struct_cities_df.createOrReplaceTempView('struct_cities')\r\n",
                "destinations_df.createOrReplaceTempView('destinations')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Task 2\r\n",
                "```\r\n",
                "Please complete the following tasks in 2 ways: \r\n",
                "•\tusing dataframe tansformations \r\n",
                "•\tusing temporary views and SQL\r\n",
                "2.1 Find top 3 most popular hotels between couples. (treat hotel as composite key of continent, country and market). Save results in dataframe and write to task2_1.csv file. \r\n",
                "2.2  Find the most popular country where hotels are booked and searched from the same country. Save results in dataframe and write to task2_2.parquet file with overwrite mode.  \r\n",
                "2.3  Find top 3 hotels where people with children are interested but not booked in the end.  Save as tempView.\r\n",
                "\r\n",
                "```"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "source": [
                "# Functions for processing\r\n",
                "from pyspark.sql import functions as F"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### 2.1 Find top 3 most popular hotels between couples. (treat hotel as composite key of continent, country and market). Save results in dataframe and write to task2_1.csv file. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Using SQL"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "source": [
                "spark.sql('''\r\n",
                "        select hotel_continent, hotel_country, hotel_market, count(*) as count \r\n",
                "        from train \r\n",
                "        where srch_adults_cnt = 2 \r\n",
                "        group by hotel_continent, hotel_country, hotel_market  \r\n",
                "        order by count(*) desc \r\n",
                "        limit 3\r\n",
                "        ''') \\\r\n",
                "        .show()"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": []
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "+---------------+-------------+------------+-------+\n",
                        "|hotel_continent|hotel_country|hotel_market|  count|\n",
                        "+---------------+-------------+------------+-------+\n",
                        "|              2|           50|         628|1190143|\n",
                        "|              2|           50|         675|1007502|\n",
                        "|              4|            8|         110| 588213|\n",
                        "+---------------+-------------+------------+-------+\n",
                        "\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": []
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Using DF transformations"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 84,
            "source": [
                "top3_hotel = train_df.select('hotel_continent', 'hotel_country', 'hotel_market') \\\r\n",
                "            .filter(train_df.srch_adults_cnt == 2) \\\r\n",
                "            .groupBy('hotel_continent', 'hotel_country', 'hotel_market').count() \\\r\n",
                "            .orderBy('count', ascending = False) \\\r\n",
                "            .limit(3) \r\n",
                "top3_hotel.show()\r\n",
                "\r\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": []
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "+---------------+-------------+------------+-------+\n",
                        "|hotel_continent|hotel_country|hotel_market|  count|\n",
                        "+---------------+-------------+------------+-------+\n",
                        "|              2|           50|         628|1190143|\n",
                        "|              2|           50|         675|1007502|\n",
                        "|              4|            8|         110| 588213|\n",
                        "+---------------+-------------+------------+-------+\n",
                        "\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": []
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Write to single file"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 91,
            "source": [
                "top3_hotel.coalesce(1).write.csv('task2_1.csv', mode = 'overwrite')"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": []
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        },
        "interpreter": {
            "hash": "1ed95a8c0d53d1577743e1092d1cab26efa8a26ceb3ea8b84542e9a65bb98046"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.6",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}